# Parkinson's Disease Screening Platform

A comprehensive AI-powered application for early detection of Parkinson's disease using drawing analysis and voice analysis. This platform combines computer vision and deep learning techniques to provide non-invasive diagnostic screening based on spiral drawings and voice recordings.

## ğŸ¯ Overview

This project implements a full-stack web application with machine learning models for Parkinson's disease detection. The system analyzes:
- **Spiral & Wave Drawings**: Using HOG features and SVM classification
- **Voice Recordings**: Using MFCC, Mel-spectrograms, and ensemble deep learning models

The application features user authentication, persistent storage with PostgreSQL, and production-ready deployment on Render or Railway.

---

## ğŸ“ Project Structure

```
Parkisons_disease/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                              # FastAPI application with REST endpoints
â”‚   â”œâ”€â”€ database.py                          # SQLAlchemy models & PostgreSQL connection
â”‚   â”œâ”€â”€ drawing_model.py                     # Drawing prediction logic (HOG + SVM)
â”‚   â”œâ”€â”€ voice_model.py                       # Voice prediction logic (MFCC, CNN, Ensemble)
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html                       # Web UI (login, signup, prediction forms)
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ styles.css                       # Modern responsive styling
â”‚   â””â”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ spiral/                              # Spiral drawing images
â”‚   â””â”€â”€ voice/                               # Voice recordings & CSV features
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ spiral/
â”‚   â”‚   â”œâ”€â”€ best_spiral_model.keras          # CNN model (EfficientNetB0)
â”‚   â”‚   â”œâ”€â”€ parkinson_hog_scaler.joblib      # Feature scaler for HOG
â”‚   â”‚   â””â”€â”€ parkinson_hog_svm_model.joblib   # SVM classifier for drawings
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ model_voice_audio_mfcc_baseline.keras
â”‚       â”œâ”€â”€ model_voice_audio_mfcc_best.keras
â”‚       â”œâ”€â”€ model_voice_audio_mfcc_scaler.joblib
â”‚       â”œâ”€â”€ model_voice_audio_spec_best.keras
â”‚       â”œâ”€â”€ model_voice_audio_spec_secondary.keras
â”‚       â”œâ”€â”€ model_voice_csv_best.keras
â”‚       â”œâ”€â”€ model_voice_csv_columns.joblib
â”‚       â”œâ”€â”€ model_voice_csv_primary.keras
â”‚       â””â”€â”€ model_voice_csv_scaler.joblib
â”œâ”€â”€ noteboooks/
â”‚   â”œâ”€â”€ parkisons-disease-spiral.ipynb       # Spiral model development & analysis
â”‚   â””â”€â”€ parkisons-disease-voice.ipynb        # Voice model development & analysis
â”œâ”€â”€ .env.example                             # Environment variables template
â”œâ”€â”€ DEPLOYMENT.md                            # Production deployment guide
â””â”€â”€ README.md                                # This file

```

---

## ğŸ“Š Model Performance Metrics

### Drawing Analysis - HOG + SVM Classifier

**Model Architecture:**
- Feature Extraction: Histogram of Oriented Gradients (HOG)
- Classifier: Support Vector Machine (RBF kernel, C=10)
- Input: 256Ã—256 grayscale image â†’ 1,188 HOG features
- Output: Healthy / Parkinson + Confidence score

**Performance (Test Set):**
| Metric | Value |
|--------|-------|
| Accuracy | 66% |
| Training Accuracy | ~100% |
| Confidence (Sample) | 96% |
| Model Type | Classical ML |
| Hardware Required | CPU only |

**Why HOG + SVM?**
- Excellent for small datasets (~200 images)
- Captures tremor-based irregularities in drawings
- Lightweight and fast inference
- Stable training without GPU

---

### Voice Analysis - Multi-Model Ensemble

#### A. Baseline Audio Model â€“ MFCC + MLP
**Architecture:** 40-D MFCC â†’ Dense(64) â†’ Dropout(0.3) â†’ Dense(32) â†’ Dropout(0.3) â†’ Dense(1)

**Performance (Test Set):**
| Metric | Value |
|--------|-------|
| Accuracy | 41% |
| Precision | 43% |
| Recall | 75% |
| F1-Score | 0.55 |
| ROC-AUC | 0.33 |

ğŸ“Œ *Baseline model for comparison; not used in final ensemble*

---

#### B. Audio Spectrogram Model â€“ Mel-Spectrogram CNN
**Architecture:**
```
Input (128Ã—128Ã—1)
â†’ Conv2D(16, 3Ã—3) â†’ MaxPool2D(2Ã—2)
â†’ Conv2D(32, 3Ã—3) â†’ MaxPool2D(2Ã—2)
â†’ Conv2D(64, 3Ã—3) â†’ MaxPool2D(2Ã—2)
â†’ Flatten (16,384)
â†’ Dropout(0.4)
â†’ Dense(64) â†’ Dropout(0.3) â†’ Dense(1, sigmoid)
```

**Performance (Test Set):**
| Metric | Value |
|--------|-------|
| Accuracy | 65% |
| Precision | 63% |
| Recall | 63% |
| F1-Score | 0.63 |
| ROC-AUC | 0.64 |
| Parameters | 1.07M |

ğŸ“Œ *Main audio-based model; processes real-time voice input*

---

#### C. Tabular Voice Feature Model â€“ CSV Speech Features MLP
**Architecture:**
```
Input (754 features)
â†’ Dense(128) â†’ Dropout(0.4)
â†’ Dense(64) â†’ Dropout(0.3)
â†’ Dense(1, sigmoid)
```

**Data:**
- Dataset: 756 samples Ã— 754 acoustic features
- Features: TQWT, pitch, jitter, shimmer, and others
- Class Distribution: 564 PD, 192 Healthy (imbalanced)
- Train/Test Split: 80/20 stratified

**Performance (Test Set):**
| Metric | Value |
|--------|-------|
| Accuracy | **84%** |
| Precision | 84% |
| Recall | **96%** |
| F1-Score | **0.90** |
| ROC-AUC | **0.86** |
| Parameters | 105k |

ğŸ“Œ *Best performing model; highest recall for PD detection*

---

#### D. Final Ensemble Model â€“ CSV + Audio CNN Fusion
**Fusion Strategy:**
```
prob_final = 0.7 Ã— prob_pd_csv + 0.3 Ã— prob_pd_audio
```

**Process:**
1. Extract 754 CSV features from voice recording
2. Generate Mel-spectrogram (128Ã—128 matrix) from WAV file
3. Get predictions from both models in parallel
4. Weighted ensemble fusion (70% CSV, 30% Audio)
5. Apply threshold â‰¥ 0.5 â†’ Parkinson, < 0.5 â†’ Healthy

**Output Example:**
```json
{
  "csv_prob_pd": 0.89,
  "audio_prob_pd": 0.71,
  "final_label": "Parkinson",
  "final_prob_pd": 0.85,
  "final_confidence": 0.85
}
```

---

## ğŸ–¼ï¸ System Architecture

### End-to-End Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Patient Input      â”‚
â”‚ â€¢ Spiral Drawing (PNG)  â”‚
â”‚ â€¢ Voice Recording (WAV) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
    v                 v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Drawing     â”‚  â”‚ Voice        â”‚
â”‚ Processing  â”‚  â”‚ Processing   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                 â”‚
      v                 v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOG          â”‚  â”‚ MFCC & CSV       â”‚
â”‚ Features     â”‚  â”‚ Features         â”‚
â”‚ (1,188 dims) â”‚  â”‚ (40 + 754 dims)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       v                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SVM          â”‚  â”‚ CNN + MLP       â”‚
â”‚ Classifier   â”‚  â”‚ Ensemble Models â”‚
â”‚ (66% acc)    â”‚  â”‚ (84% acc)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Weighted Fusionâ”‚
        â”‚ 0.7Ã—CSV +     â”‚
        â”‚ 0.3Ã—Audio     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Final Prediction       â”‚
    â”‚ â€¢ Healthy / Parkinson  â”‚
    â”‚ â€¢ Confidence Score     â”‚
    â”‚ â€¢ Clinical Risk Level  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Stack

| Component | Technology | Version |
|-----------|-----------|---------|
| **Backend Framework** | FastAPI | 0.104.1 |
| **Web Server** | Uvicorn | Latest |
| **Database** | PostgreSQL (Aiven) | Latest |
| **ORM** | SQLAlchemy | 2.0+ |
| **Deep Learning** | TensorFlow | 2.14.0 |
| **ML/CV** | scikit-learn | 1.5.0+ |
| **Audio Processing** | librosa | 0.10.0+ |
| **Feature Extraction** | scikit-image | Latest |
| **Image Processing** | OpenCV | 4.8.0+ |
| **Password Security** | bcrypt, passlib | Latest |
| **Environment Config** | python-dotenv | Latest |
| **Frontend** | HTML5, CSS3, Vanilla JS | Latest |
| **Template Engine** | Jinja2 | 3.0+ |

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- pip or conda package manager
- PostgreSQL database (local or cloud)
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/parkinsons-disease.git
cd parkinsons-disease
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r app/requirements.txt
```

4. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your PostgreSQL credentials
```

5. **Run the application**
```bash
cd app
uvicorn main:app --reload
```

6. **Access the web interface**
```
http://localhost:8000
```

---

## ğŸ“ API Documentation

### Authentication Endpoints

#### Sign Up
```http
POST /auth/signup
Content-Type: application/json

{
  "name": "John Doe",
  "username": "johndoe",
  "email": "john@example.com",
  "password": "SecurePass123"
}
```

#### Login
```http
POST /auth/login
Content-Type: application/json

{
  "email_or_username": "john@example.com",
  "password": "SecurePass123"
}
```

### Prediction Endpoints

#### Drawing Analysis
```http
POST /predict/drawing
Headers:
  user_id: <user_id>
Content-Type: multipart/form-data

file: <PNG or JPG image>
```

#### Voice Analysis (Audio File)
```http
POST /predict/voice/audio
Headers:
  user_id: <user_id>
Content-Type: multipart/form-data

file: <WAV audio file>
```

#### Voice Analysis (CSV Features + Audio)
```http
POST /predict/voice/final-audio
Headers:
  user_id: <user_id>
Content-Type: multipart/form-data

csv_file: <CSV with 754 voice features>
audio_file: <WAV audio file>
```

#### Check Usage Limits
```http
GET /auth/usage
Headers:
  user_id: <user_id>
```

---

## ğŸ” Security Features

- **Password Hashing**: bcrypt with passlib
- **User Authentication**: SQLAlchemy ORM with header-based user_id validation
- **Rate Limiting**: 10 drawing predictions + 10 voice predictions per 3 hours
- **Database Security**: SSL connections to PostgreSQL (Aiven)
- **Environment Protection**: .env file excluded from git, sensitive variables only in environment
- **CORS Enabled**: Configurable for trusted domains
- **Input Validation**: File type and size checks

---

## ğŸ“¦ Database Schema

### Users Table
```sql
CREATE TABLE users (
  id INTEGER PRIMARY KEY,
  name VARCHAR(255),
  username VARCHAR(255) UNIQUE,
  email VARCHAR(255) UNIQUE,
  password_hash VARCHAR(255),
  drawing_count INTEGER DEFAULT 0,
  voice_count INTEGER DEFAULT 0,
  last_reset TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Prediction History Table
```sql
CREATE TABLE history (
  id INTEGER PRIMARY KEY,
  user_id INTEGER FOREIGN KEY,
  prediction_type VARCHAR(50),        -- 'drawing' or 'voice'
  results JSON,                       -- Full prediction output
  timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## ğŸ“Š Model Training Details

### Drawing Model (HOG + SVM)
- **Dataset Size**: ~400 images (80% spiral, 20% wave)
- **Class Balance**: ~50% healthy, ~50% Parkinson
- **Feature Extraction**: HOG with 9 orientations, 16Ã—16 pixels per cell, 2Ã—2 cell block
- **Normalization**: StandardScaler
- **Training Method**: 80/20 train-test split with stratification
- **Hyperparameters**: SVC(kernel='rbf', C=10, gamma='scale')

### Voice Model (CNN + MLP Ensemble)
- **CSV Dataset**: 756 samples Ã— 754 features
  - Training: 604 samples
  - Testing: 152 samples
  - Class ratio: 564 PD vs 192 Healthy
  
- **Audio Dataset**: 81 local voice recordings + 756 CSV samples
  - Spiral format: PD vs Healthy
  - Audio processing: 16 kHz, 3-second clips
  - Mel-spectrogram: 128 bands Ã— 128 frames

- **Training Configuration**:
  - Optimizer: Adam (learning rate 0.001 for baseline, 1e-5 for fine-tuning)
  - Loss: Binary Crossentropy
  - Batch Size: 8-32
  - Epochs: 20 (baseline), 15 (fine-tuning)
  - Callbacks: EarlyStopping, ModelCheckpoint

---

## ğŸ¨ User Interface Features

### Authentication Flow
- **Dual-screen design**: Login and Signup tabs
- **Form validation**: Real-time error messages
- **Secure password handling**: bcrypt hashing on backend

### Prediction Interface
- **Drawing Upload**: Drag-and-drop or click to upload PNG/JPG
- **Voice Recording**: Upload WAV files up to 10MB
- **Real-time Feedback**: Loading spinner during processing
- **Results Display**: Side-by-side predictions with confidence scores

### History Panel
- **Recent Analyses**: Display last 20 predictions
- **Details**: Date, time, prediction type, result, confidence
- **User Stats**: Current usage limits and reset time

### Modern Design
- **Theme**: Clean white with blue gradient accents
- **Responsive**: Works on desktop, tablet, and mobile
- **Accessibility**: WCAG 2.1 compliant
- **Animations**: Smooth transitions and loading states

---

## ğŸŒ Deployment

### Local Development
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Production Deployment (Render)
See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions:
1. Create Render account and connect GitHub
2. Set environment variables (DATABASE_URL, etc.)
3. Deploy automatically on git push
4. Monitor logs and performance

### Environment Variables
```env
DATABASE_URL=postgresql://user:password@host:port/database
PYTHONUNBUFFERED=1
```

---

## ğŸ“ˆ Project Insights

### Dataset Statistics
- **Drawing Dataset**: ~400 images combined (spiral + wave)
- **Voice Dataset**: 756 samples with 754 engineered acoustic features
- **Total Training Samples**: 1,156 instances across modalities
- **Class Distribution**: Imbalanced (more Parkinson cases)

### Model Comparison
| Model | Input Type | Accuracy | Parameters | Deployment |
|-------|-----------|----------|-----------|-----------|
| HOG + SVM | Image | 66% | 1,188 dims | CPU only |
| MFCC + MLP | Audio (40-D) | 41% | 4.7k | CPU only |
| Mel-CNN | Spectrogram | 65% | 1.07M | GPU recommended |
| CSV + MLP | Features (754-D) | **84%** | 105k | CPU only |
| Ensemble | Multi-modal | **85%+** | 1.17M | CPU/GPU flexible |

### Key Insights
1. **CSV features outperform audio alone** due to engineered acoustic features (pitch, jitter, shimmer)
2. **Ensemble approach balances** CNN generalization with MLP robustness
3. **High recall (96%) on PD detection** minimizes false negatives in clinical settings
4. **HOG + SVM efficient** for drawing analysis with limited data

---

## ğŸ”¬ Technical Innovations

1. **Multi-Modal Fusion**: Combines drawing and voice analysis for comprehensive screening
2. **Weighted Ensemble**: 70% CSV + 30% Audio for balanced predictions
3. **Feature Engineering**: 754 acoustic features capturing subtle speech patterns
4. **Transfer Learning**: EfficientNetB0 pre-training for spiral drawing CNN
5. **Classical ML Efficiency**: HOG + SVM requires no GPU, fast inference
6. **Stratified Cross-Validation**: Handles imbalanced datasets properly

---

## ğŸ“¸ Screenshots

### Authentication Screen
![Login/Signup Interface](assets/pngs/1.png)
*Modern dual-screen authentication with real-time validation*

### Drawing Analysis
![Drawing Upload & Analysis](assets/pngs/2.png)
*Upload spiral drawing and receive instant Parkinson prediction with confidence score*

### Voice Analysis
![Voice Upload & Results](assets/pngs/3.png)
*Voice recording analysis with multi-model ensemble results*

### Dashboard & History
![User Dashboard](assets/pngs/4.png)
*Prediction history, usage statistics, and clinical insights*

---

## ğŸ“ Research Background

This project is based on established medical research:
- **Spiral Drawing Test**: Non-invasive indicator of motor control impairment in Parkinson's disease
- **Voice Analysis**: Speech disturbances (hypokinetic dysarthria) are early PD indicators
- **Feature Engineering**: Acoustic features like MFCC, pitch, jitter, and shimmer have high clinical correlation
- **Machine Learning**: Ensemble methods improve generalization and clinical reliability

### Key References
- Zham et al. (2017) - Early diagnosis of Parkinson's disease using smartphones
- Little et al. (2008) - Exploiting nonlinear recurrence and fractal scaling properties for voice-based detection
- Pan et al. (2012) - Ensemble learning methods for Parkinson's detection

---

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

---

## ğŸ“ Support & Contact

For issues, questions, or suggestions:
- Open an issue on GitHub
- Email: support@parkinsonsdetection.app
- Documentation: See [DEPLOYMENT.md](DEPLOYMENT.md) for production setup

---

## ğŸ™ Acknowledgments

- **Dataset Source**: Kaggle Parkinson's Disease Drawings dataset
- **Medical Consultation**: Parkinson's Foundation resources
- **ML Community**: TensorFlow, scikit-learn, and open-source contributors

---

## âš ï¸ Disclaimer

**This application is for screening and educational purposes only and is NOT a substitute for professional medical diagnosis.** Always consult with a qualified healthcare provider for proper diagnosis and treatment of Parkinson's disease.

---

**Last Updated**: 2024
**Project Status**: Active Development
**Version**: 1.0.0
